{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmdarima.arima import AutoARIMA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import date as dt, timedelta\n",
    "import yfinance as yf\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime as dt\n",
    "import pandas_datareader as web\n",
    "from dateutil.relativedelta import *\n",
    "import yfinance as yf\n",
    "from yahoofinancials import YahooFinancials\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the df from SQL table\n",
    "def make_con():\n",
    "\n",
    "    conn=pymysql.connect(host='localhost',\n",
    "                         port=int(3306),\n",
    "                         user='root',\n",
    "                         passwd='Calculator1',\n",
    "                         db='Options')\n",
    "    \n",
    "    current_date = pd.datetime.today().strftime('%Y-%m-%d') #this can be used instead of attributes above\n",
    "\n",
    "    df_all =pd.read_sql_query(f'SELECT * FROM options.anamolous;',conn)\n",
    "    \n",
    "    max_date = (pd.to_datetime(df_all.Time.max()) - BDay(5)).strftime('%Y-%m-%d')\n",
    "    df_all = df_all[df_all.Time <=max_date]\n",
    "    df_all = df_all.reset_index()\n",
    "    df_all = df_all[['Symbol', 'Time', 'per_change', 'Calls', 'Puts', 'Put/Call','TotalVolume', 'Orient']]\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = make_con()\n",
    "# df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_list = list(df_all.Time.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_data():\n",
    "    \n",
    "    df_all = make_con()\n",
    "    time_list = list(df_all.Time.unique())\n",
    "\n",
    "    no_list = ['2022-06-03']\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    for t in time_list:\n",
    "\n",
    "            df = df_all[df_all.Time == t].reset_index(drop=True)\n",
    "            stocks = df.Symbol.unique().tolist()\n",
    "\n",
    "            start = df.Time.min()\n",
    "            end = (pd.to_datetime(start) + BDay(7)).strftime('%Y-%m-%d')\n",
    "\n",
    "            new = yf.download(stocks, start, end, auto_adjust=True, progress=True)['Close']\n",
    "            new = new.T\n",
    "\n",
    "            if new.shape[1] == 7:\n",
    "                new = new.iloc[:,:-1]\n",
    "                print('length of dataframe was 7 and deleted last column')\n",
    "            elif new.shape[1] == 6:\n",
    "                print('length of dataframe was 6')\n",
    "\n",
    "            new = new.reset_index()\n",
    "            new.columns = ['Symbol','cp', 'first', 'second', 'third', 'fourth', 'fifth']\n",
    "\n",
    "            merged_df = df.merge(new, how='inner', left_on='Symbol', right_on='Symbol')\n",
    "\n",
    "            merged_df['d1_%chng'] = (merged_df['first'] - merged_df['cp'])/merged_df['cp']*100\n",
    "            merged_df['d2_%chng'] = (merged_df['second'] - merged_df['cp'])/merged_df['cp']*100\n",
    "            merged_df['d3_%chng'] = (merged_df['third'] - merged_df['cp'])/merged_df['cp']*100\n",
    "            merged_df['d4_%chng'] = (merged_df['fourth'] - merged_df['cp'])/merged_df['cp']*100\n",
    "            merged_df['d5_%chng'] = (merged_df['fifth'] - merged_df['cp'])/merged_df['cp']*100\n",
    "\n",
    "            final_df = pd.concat([final_df, merged_df],axis=0)\n",
    "\n",
    "    return final_df, merged_df, new, df, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  22 of 22 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  25 of 25 completed\n",
      "length of dataframe was 6\n",
      "[*********************100%***********************]  26 of 26 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  11 of 11 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  7 of 7 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  6 of 6 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  6 of 6 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  10 of 10 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  11 of 11 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  11 of 11 completed\n",
      "length of dataframe was 6\n",
      "[*********************100%***********************]  4 of 4 completed\n",
      "length of dataframe was 6\n",
      "[*********************100%***********************]  10 of 10 completed\n",
      "length of dataframe was 6\n",
      "[*********************100%***********************]  7 of 7 completed\n",
      "length of dataframe was 6\n",
      "[*********************100%***********************]  13 of 13 completed\n",
      "length of dataframe was 6\n",
      "[*********************100%***********************]  12 of 12 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  10 of 10 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "length of dataframe was 6\n",
      "[*********************100%***********************]  11 of 11 completed\n",
      "length of dataframe was 6\n",
      "[*********************100%***********************]  8 of 8 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  8 of 8 completed\n",
      "length of dataframe was 7 and deleted last column\n",
      "[*********************100%***********************]  13 of 13 completed\n",
      "length of dataframe was 7 and deleted last column\n"
     ]
    }
   ],
   "source": [
    "final_df, merged_df, new, df, t = get_yahoo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_excel('final_along_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
